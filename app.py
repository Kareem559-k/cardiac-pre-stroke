import streamlit as st
import numpy as np
import pandas as pd
import joblib, os
from scipy.stats import skew, kurtosis
from wfdb import rdrecord
import matplotlib.pyplot as plt
from io import BytesIO

# ğŸ©º Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="ECG Stroke Predictor", page_icon="ğŸ’™", layout="centered")
st.title("ğŸ«€ ECG Stroke Prediction (Micro-Dynamics v2)")
st.caption("Upload ECG (.hea/.dat) or feature file (CSV/NPY). Extracts 17 micro-dynamic features and predicts stroke risk.")

# ====== ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ======
MODEL_PATH = "meta_logreg.joblib"
SCALER_PATH = "scaler.joblib"
IMPUTER_PATH = "imputer.joblib"

st.markdown("### Upload model files (if not found in repo):")
up_model = st.file_uploader("meta_logreg.joblib", type=["joblib", "pkl"])
up_scaler = st.file_uploader("scaler.joblib", type=["joblib", "pkl"])
up_imputer = st.file_uploader("imputer.joblib", type=["joblib", "pkl"])

if st.button("Save uploaded files"):
    if up_model: open(MODEL_PATH, "wb").write(up_model.read())
    if up_scaler: open(SCALER_PATH, "wb").write(up_scaler.read())
    if up_imputer: open(IMPUTER_PATH, "wb").write(up_imputer.read())
    st.success("âœ… Uploaded files saved. Click 'Rerun' to load them.")

def load_artifacts():
    if not (os.path.exists(MODEL_PATH) and os.path.exists(SCALER_PATH) and os.path.exists(IMPUTER_PATH)):
        st.error("Missing model files. Please upload them above.")
        return None, None, None
    model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    imputer = joblib.load(IMPUTER_PATH)
    return model, scaler, imputer

model, scaler, imputer = load_artifacts()
if model is None:
    st.stop()

# ====== Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª (17 Ù…ÙŠØ²Ø©) ======
def extract_micro_features(sig):
    sig = np.asarray(sig, dtype=float)
    diffs = np.diff(sig)
    return np.array([
        np.mean(sig), np.std(sig), np.min(sig), np.max(sig),
        np.ptp(sig), np.sqrt(np.mean(sig**2)), np.median(sig),
        np.percentile(sig, 25), np.percentile(sig, 75),
        skew(sig), kurtosis(sig),
        np.mean(np.abs(diffs)), np.std(diffs), np.max(diffs),
        np.mean(np.square(diffs)), np.percentile(diffs, 90), np.percentile(diffs, 10)
    ])

# ====== Ø¶Ø¨Ø· Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø¯Ù‚Ø© ======
def align(X, expected, name):
    if X.ndim == 1:
        X = X.reshape(1, -1)
    if expected is None:
        return X
    if X.shape[1] < expected:
        add = expected - X.shape[1]
        X = np.hstack([X, np.zeros((X.shape[0], add))])
        st.warning(f"âš ï¸ Added {add} placeholders for {name}.")
    elif X.shape[1] > expected:
        cut = X.shape[1] - expected
        X = X[:, :expected]
        st.warning(f"âš ï¸ Trimmed {cut} features for {name}.")
    return X

# ====== ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ======
st.markdown("---")
mode = st.radio("Select input type:", ["Raw ECG (.hea + .dat)", "Feature file (CSV / NPY)"])
threshold = st.slider("Decision threshold (prob â‰¥ this â†’ High Risk)", 0.1, 0.9, 0.5, 0.01)

# ====== Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙØ³ÙŠØ± ======
def explain(prob):
    if prob >= threshold:
        return f"ğŸ”´ **High stroke risk (probability {prob:.2%})**"
    else:
        return f"ğŸŸ¢ **Normal ECG (probability {prob:.2%})**"

# ===========================================================
# ğŸŒ¡ï¸ ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª ECG Ø§Ù„Ø®Ø§Ù…
# ===========================================================
if mode == "Raw ECG (.hea + .dat)":
    hea_file = st.file_uploader("Upload .hea file", type=["hea"])
    dat_file = st.file_uploader("Upload .dat file", type=["dat"])

    if hea_file and dat_file:
        tmp = hea_file.name.replace(".hea", "")
        open(hea_file.name, "wb").write(hea_file.read())
        open(dat_file.name, "wb").write(dat_file.read())

        try:
            rec = rdrecord(tmp)
            sig = rec.p_signal[:, 0] if rec.p_signal.ndim > 1 else rec.p_signal

            st.line_chart(sig[:2000], height=200)
            st.caption("Preview of first 2000 ECG samples")

            # ====== Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© ======
            feats = extract_micro_features(sig).reshape(1, -1)
            feats = align(feats, len(imputer.statistics_), "Imputer")
            X_imp = imputer.transform(feats)
            X_imp = align(X_imp, len(scaler.mean_), "Scaler")
            X_scaled = scaler.transform(X_imp)
            X_scaled = align(X_scaled, model.n_features_in_, "Model")

            # ====== Ø§Ù„ØªÙ†Ø¨Ø¤ ======
            prob = model.predict_proba(X_scaled)[0, 1]
            st.subheader("ğŸ” Prediction Result")
            st.write(explain(prob))

            # ====== Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ======
            cols = ["mean","std","min","max","ptp","rms","median","p25","p75",
                    "skew","kurtosis","mean_diff_abs","std_diff","max_diff",
                    "mean_diff_sq","p90_diff","p10_diff"]
            df_feats = pd.DataFrame(feats, columns=cols)
            df_feats["Stroke Probability"] = prob
            st.dataframe(df_feats.style.format(precision=5))

            # ====== Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ ======
            fig, ax = plt.subplots(figsize=(4, 1.4))
            ax.barh(["Stroke Risk"], [prob], color="#ff6b6b" if prob >= threshold else "#6cc070")
            ax.set_xlim(0, 1)
            ax.set_xlabel("Probability")
            st.pyplot(fig)

            # ====== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ======
            csv_buf = BytesIO()
            df_feats.to_csv(csv_buf, index=False)
            st.download_button("â¬‡ï¸ Download Results (CSV)", data=csv_buf.getvalue(),
                               file_name="ecg_prediction_results.csv", mime="text/csv")

        except Exception as e:
            st.error(f"âŒ Error reading ECG: {e}")

# ===========================================================
# ğŸ§¾ ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Features (CSV/NPY)
# ===========================================================
else:
    uploaded = st.file_uploader("Upload feature file (CSV/NPY)", type=["csv", "npy"])
    if uploaded:
        try:
            X = pd.read_csv(uploaded).values if uploaded.name.endswith(".csv") else np.load(uploaded)
            X = align(X, len(imputer.statistics_), "Imputer")
            X_imp = imputer.transform(X)
            X_imp = align(X_imp, len(scaler.mean_), "Scaler")
            X_scaled = scaler.transform(X_imp)
            X_scaled = align(X_scaled, model.n_features_in_, "Model")

            probs = model.predict_proba(X_scaled)[:, 1]
            preds = np.where(probs >= threshold, "âš ï¸ High Risk", "âœ… Normal")
            df_out = pd.DataFrame({
                "Sample": np.arange(1, len(probs) + 1),
                "Probability": probs,
                "Prediction": preds
            })

            st.subheader("ğŸ“Š Batch Prediction Summary")
            st.dataframe(df_out.head(10).style.format({"Probability": "{:.4f}"}))
            st.line_chart(probs, height=150)

            buf = BytesIO()
            df_out.to_csv(buf, index=False)
            st.download_button("â¬‡ï¸ Download All Predictions (CSV)",
                               data=buf.getvalue(),
                               file_name="ecg_batch_predictions.csv",
                               mime="text/csv")

        except Exception as e:
            st.error(f"âŒ Error processing file: {e}")

# ===========================================================
# â„¹ï¸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª
# ===========================================================
st.markdown("---")
st.markdown("""
### â„¹ï¸ Notes:
- This version generates **17 micro-dynamic features** to match your model input.
- If probabilities always look similar, try adjusting the threshold slider above.
- For research/educational use only â€” not a medical diagnosis tool.
""")
